---
title: "FinalWriteUp"
author: "Apache Juntion Armchairs: Ellie, Ryan, Sude and Darren"
date: "4/20/2020"
output: 
  pdf_document:
    fig_width: 5
    fig_height: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning=FALSE, 
                      message=FALSE)
options(tinytex.verbose = TRUE)
suppressMessages(library("tidyverse"))
```

### Section 1: Introduction














### Section 2: Regression Analysis:

```{r}
library(tidyverse)
library(knitr)
library(broom)
library(ggplot2)
library(openintro)
library(nnet)
library(patchwork)
library(pROC)
library(plotROC)
library(psych)
library(RColorBrewer) #custom color palettes
#wrangle and model spatial data
library(sf)
library(spatialreg)
library(spdep)
library(anchors)
library(viridis)
library(RColorBrewer)
library("ggrepel")
library(modelr)
```

```{r}
gentdata <- read_csv("data/gentdata.csv", col_names = TRUE, col_types = cols())
manual <- read_csv("ImportR.csv", col_names = TRUE, col_types = cols())
manual <- manual %>% 
  mutate(black = 100*(black17/total17 - black10/total10)) %>%
  mutate(collegewhite = 100*(collegewhite17/total17 - collegewhite10/total10)) %>%
  mutate(nodiploma = 100*(nodiploma17/total17 - nodiploma10/total10)) %>%
  mutate(highschoolgrad = 100*(highschoolgrad17/total17 - highschoolgrad10/total10)) %>%
  mutate(collegedegree = 100*(collegedegree17/total17 - collegedegree10/total10)) %>%
  mutate(collegedegree = 100*(collegedegree17/total17 - collegedegree10/total10)) %>%
  mutate(early_late = 100*(early_late17/employed17 - early_late10/employed10)) %>%
  mutate(privateschool = 100*(privateschool17/totalpop17 - privateschool10/totalpop10))
```

```{r}
manual <- manual %>% 
  mutate(moved17=as.numeric(moved17)) %>% 
  mutate(moved10=as.numeric(moved10)) %>%
  mutate(moved = moved17-moved10) %>%
  mutate(homeprice17=as.numeric(homeprice17)) %>% 
  mutate(homeprice10=as.numeric(homeprice10)) %>%
  mutate(homeprice_med = (homeprice17 - homeprice10)) %>%
  mutate(income2017=as.numeric(income2017)) %>% 
  mutate(income2010=as.numeric(income2010)) %>%
  mutate(income_med = (income2017 - income2010))
names(manual)[1] <- "geoid"
```

```{r}
manual <- manual %>% 
  mutate(income_med=as.numeric(income)) %>% 
  mutate(homeprice_med=as.numeric(homeprice)) %>% 
  mutate(collegewhite=as.numeric(collegewhite)) %>% 
  mutate(whitecollar=as.numeric(whitecollar)) %>% 
  mutate(early_late=as.numeric(early_late)) %>% 
  mutate(highschoolgrad=as.numeric(highschoolgrad)) %>% 
  mutate(collegedegree=as.numeric(collegedegree)) %>% 
  mutate(nodiploma=as.numeric(nodiploma)) %>% 
  mutate(black=as.numeric(black)) %>% 
  mutate(privateschool=as.numeric(privateschool))
```

```{r}
gent_rural <- gentdata %>% 
  group_by(geoid) %>% 
  summarise(rural)
manual <- inner_join(manual, gent_rural, by="geoid")
```


```{r}
mean_homeprice <- manual %>%
  summarise(mean = mean(homeprice_med, na.rm = T)) %>%
  pull()
manual <- manual %>%
  mutate(homeprice_med = if_else(is.na(homeprice_med), mean_homeprice, homeprice_med))
mean_income <- manual %>%
  summarise(mean = mean(income_med, na.rm = T)) %>%
  pull()
manual <- manual %>%
  mutate(income_med = if_else(is.na(income_med), mean_income, income_med))
mean_income <- manual %>%
  summarise(mean = mean(income_med, na.rm = T)) %>%
  pull()
manual <- manual %>%
  mutate(income_med = if_else(is.na(income_med), mean_income, income_med))
manual <- manual %>%
  mutate(moved = if_else(is.na(moved), 0, moved))

manual <- replace.value(manual,c("black","collegewhite","nodiploma","highschoolgrad","collegedegree","privateschool", "early_late", "moved"), "NaN", as.double(0))


```


The distribution of change in Black population:

In order to assess whether gentrification is taking place in an area we looked at the change in the Black population. 
First we looked at the distribution of change in Black population to determine an appropriate threshold.

```{r}
ggplot(data = manual, mapping = aes(x = black)) + 
  geom_histogram()
(sd(manual$black))
```

std deviation is =  6.88333. We will use this value (-6.88333) as the threshold to determine if gentrification has occurred in a census tract. If a tract has experienced more than a -6.88333 PP change in the Black population, we will consider that census tract "gentrified." Even though the mean is not exactly at 0, it is close enough that we feel one standard deviation away from 0 is a sufficient threshold for gentrification.

Next, we create a new variable "gent" to represent whether a census tract is gentrified or not. As described above, ff a census tract have less than or equal to -6.88333 percent change in Black population then we classify the region as gentrified and the variable gent will be "1" otherwise the region will not be classified as gentrified and gent will be "0".

```{r}
manual <- manual %>% 
  mutate(gent = case_when(black>(-6.88333) ~ 0, black<=(-6.88333) ~ 1))

manual <- manual %>%
  mutate(gent = if_else(is.na(gent), 0, gent))
manual %>% 
  count(gent) 
```

In our data set we have 246 observations that are not considered gentrified and 42 that are.


After examining the Univariate and Bi-variate EDA (located in section 6) we proceeded with our analysis without any additional transformations because each predictor variable is normally distributed around 0 and the relationship between the response variable "gent" and the predictor variables are all each roughly normal.


###Part I: Location of Gentrification

In part I, the following research question will be examined:

Where in the Research Triangle (counties including Durham, Wake, Orange and Chatham) is gentrification occurring the most?

Recoding our response variable to "1" if change in black population is <= "-6.765" or one standard deviation below 0 (roughly the mean) and equal to "0" if >  "6.765" in order visualize and eventually create a logistic model:

```{r}
manual <- manual %>% 
  mutate(gent = case_when(black>(-6.765474) ~ 0, black<=(-6.765474) ~ 1))
manual <- manual %>%
  mutate(gent = if_else(is.na(gent), 0, gent))
manual %>% 
  count(gent) 
```

In order to determine the locations of gentrification we use spatial data to conduct our analysis:

```{r}
shape <- read_sf(dsn = "data", layer = "triangletracts")
shape <- shape %>%
  mutate(geoid = as.character(AFFGEOID)) 
merged <- inner_join(shape, manual, by = "geoid") %>%
  mutate(.rownames = 1:n())
```


Plotting research triangle area (counties: Chatham, Durham, Orange and Wake):
We will be looking only at this region and conducting our analysis of the census tracts shown below

I coulnt knit--> make sure to make code chunck again!!!

``{r}
shapeurban <- read_sf(dsn = "data", layer = "MunicipalBoundaries")

shapeurban_aea <- st_transform(shapeurban, st_crs(shape))

cities <- cbind(shapeurban_aea, st_coordinates(st_centroid(shapeurban_aea)))

cities<- as.data.frame(cities)
```

``{r}
ggplot(data = merged) +
  geom_sf() +
  labs(title = "Research Triangle", 
       x = "Longitude", y = "Latitude") +
  geom_text_repel(data = cities, aes(x = X, y = Y, label = MunicipalB), 
        fontface = "bold", nudge_x = c(1, -1.5, 2, 2, -1), nudge_y = c(0.25, 
            0.25, 0.5, 0.5, 0.5))


```



Next we want to visualize which regions in the research triangle area have experienced gentrification:

```{r}
ggplot(data = merged, aes(fill = gent)) +
  geom_sf() +
  labs(title = "Research Triangle", 
       subtitle = "Gentrification by census tract") +
  theme_void() +
  scale_fill_distiller(palette = 'GnBu', guide = "legend", n="Gentrified", direction=1, type="qual") 
```

The census tracts shown above in blue are classified as gentrified and those that are yellow are not. 

We hypothesized that whether a census tract is in an urban or rural area would impact whether that region had also experienced gentrification. In order to determine urban vs rural impact on gentrification, we recoded the variable "rural" to be equal to "1" if the census tract is considered to be rural and "0" if the census tract is in an urban area.

```{r}
merged <- merged %>% 
    mutate(rural = recode(rural, 
                      "Rural" = "1", 
                      "Urban" = "0"))
merged <- merged %>% 
  mutate(rural=as.character(rural)) %>% 
  mutate(rural=as.numeric(rural))
```

Next, we want to visualize which regions in the research triangle area are considered urban/rural:

```{r}
ggplot(data = merged, aes(fill = rural)) +
  geom_sf() +
  labs(title = "Research Triangle", 
       subtitle = "Urban areas by census tract") +
  theme_void() +
  scale_fill_distiller(palette = '', guide = "legend", direction=1)
```

By comparing the locations of gentrified tracts to urban areas, we can see that almost all gentrified tracts are in urban areas. Moreover, many of the gentrified tracts appear to be in and around city centers. This makes sense--we tend to think of gentrification as affecting highly urbanized downtown areas.














###Part 2: Factors Associated with Gentrification

In part 2, the following research question will be examined:

What factors are associated with and what are the strongest predictors of the gentrification of these areas?


In order to predict where gentrification is taking place we again looked at the change in the Black population. We use the catagorical variable created in part one above, "gent" where a "1" is coded for census tracts that we classify as gentrified and "0" for census tracts which have not been gentrified. Since gent is a catagorical variable with 2 outcomes we fit a logistic model.

```{r}
model <- glm(gent ~ collegewhite + whitecollar + privateschool + nodiploma + highschoolgrad + collegedegree + income_med + homeprice_med + early_late + moved, 
                  data = manual, family="binomial")
tidy(model, conf.int = TRUE) %>%
  kable(format = "markdown", digits = 5)
  
```

Next we use backward selection to find the optimal model because not every variable is significant.

```{r}
model_aic <- step(model, direction = "backward", conf.int=T)
tidy(model_aic, conf.int = TRUE) %>%
  kable(format = "markdown", digits = 5)
```

Logistic model predicting gentrification:

`log(pi_hat/(1-pi_hat)) = -2.2308 + (0.1084)*(collegewhite) - (0.0569)*(whitecollar) + (0.1347)*(nodiploma) + (0.0694)*(highschoolgrad) + (0.00001)*(homeprice_med)`

We originally hypothesized that whether a census tract is in an urban or rural area would impact whether that region had also experienced gentrification. In order to determine urban vs rural impact we visualized where the gentrified areas were and compared to the map of urban vs. rural regions. In the visualizations, many of the gentrified tracts appeared to be in and around city centers. Now, we want to determine if the variable "rural" is significant and should be added to our model.


We create a full model that includes "rural" and conduct a drop in deviance test to determine if we should add "rural" to the model: 

The null hypothesis is that the coefficient for rural does not add significant information to our model. The alternative hypothesis is that the coefficient for rural does add significant information to our model.

H0: B_rural = 0 
HA: B_rural != 0 

```{r}
model_aic_full <- glm(gent ~ collegewhite + whitecollar + nodiploma + highschoolgrad + homeprice_med + rural, data=manual, family= "binomial" )
tidy(model_aic_full)
```


```{r}
(dev_m <- glance(model_aic)$deviance)
(dev_full <- glance(model_aic_full)$deviance)
(test_stat <- dev_m - dev_full)
```

```{r}
1- pchisq(test_stat, 1)
```

The drop in deviance test has a test statistic of 4.014 and a p-value of 0.0451.

Since the chisq p-value for adding "Rural" to the model is less than .05, we reject the null hypothesis that "Rural" is not a significant predictor of whether or not a region has experienced gentrification.

Therefore we will continue with this full model for the remainder of our analysis.


Now that we have determined Rural is a significant predictor variable, we consider adding interaction terms with rural to our model. We use k-fold cross validation to determine if we should add the interactions homeprice_med*rural and collegewhite*rural. We start by looking at the 5-fold cross validation results for the model above using the predictors: collegewhite, whitecollar, nodiploma, highschoolgrad, homeprice_med and rural. We fit a model on each training set and calcualte the testing error. Next, we repeat the same process using the predictors: collegewhite, whitecollar, nodiploma, highschoolgrad, homeprice_med, rural, and our new interaction terms,homeprice_med*rural and collegewhite*rural.


```{r}
set.seed(04012019)
ad_cv <- crossv_kfold(manual, 5)

models <- map(ad_cv$train, 
              ~ glm(gent ~ collegewhite + whitecollar + nodiploma + highschoolgrad + homeprice_med + rural, data=manual, family= "binomial"))
```

```{r}
train_mse <- map2_dbl(models, ad_cv$train, mse)
test_mse <- map2_dbl(models, ad_cv$test, mse)

mse_ad <- tibble(
  test_fold  = 1:5,
  train_mse, 
  test_mse
)

mse_ad %>%
  summarise(mean_train_mse = mean(train_mse), 
           mean_test_mse = mean(test_mse))

```


```{r}
set.seed(04012019)
ad_cv_2 <- crossv_kfold(manual, 5)

models_2 <- map(ad_cv_2$train, 
              ~ glm(gent ~ collegewhite + whitecollar + nodiploma + highschoolgrad + homeprice_med + rural + homeprice_med*rural + collegewhite*rural,  data=manual, family= "binomial"))
```

```{r}
train_mse_2 <- map2_dbl(models_2, ad_cv_2$train, mse)
test_mse_2 <- map2_dbl(models_2, ad_cv_2$test, mse)

mse_ad_2 <- tibble(
  test_fold  = 1:5,
  train_mse_2, 
  test_mse_2
)

mse_ad_2 %>%
  summarise(mean_train_mse = mean(train_mse_2), 
           mean_test_mse = mean(test_mse_2))

```

Finally we compared the estimated testing error for both models:

Model 1 (excluding interaction terms): 5.369539
Model 2 (including interaction terms): homeprice_med*rural and collegewhite*rural: 5.671572

Although the testing errors are very close, Model 1 performs better than Model 2 when predicting if a census tract is gentrified. Therefore, we will continue with the model that does not include the interaction terms.

~~~~~~~~~~~

In order to avoid collinearity of response variables we want to confirm that no two variables are highly correlated with one another. We do so by checking multicollinearity and looking for variables with high VIF (Variance Inflation Factor).

```{r}
library(rms) 
tidy(vif(model_aic_full))
```

Since the VIF for all of our variables is relatively low and none even come close to 10+, we can be confident that 
multicollinearity is not a problem in our model and none of the variables are highly correlated with one another.


###Assumptions 

In order to use the full model with the predictor variables collegewhite, whitecollar, nodiploma, highschoolgrad, 
homeprice_med, and rural, we must first test how well this model satisfies assumptions. 

For testing linearity, we will augment the model with predicted probabilities and residuals in order to examine 
binned residual plots for predicted probability and numeric variables. 

```{r}
model_aug <- augment(model_aic_full, type.predict = "response", type.residuals = "response")
model_aug
```

```{r}
arm::binnedplot(x = model_aug$.fitted, 
                y = model_aug$.resid, 
                col.int = FALSE,
                xlab = "Predicted probabilities", 
                main = "Binned Residual vs. Predicted Probability")
arm::binnedplot(x = model_aug$collegewhite, 
                y = model_aug$.resid, 
                col.int = FALSE,
                xlab = "collegewhite", 
                main = "Binned Residual vs. collegewhite")
arm::binnedplot(x = model_aug$whitecollar, 
                y = model_aug$.resid, 
                col.int = FALSE,
                xlab = "whitecollar", 
                main = "Binned Residual vs. whitecollar")
arm::binnedplot(x = model_aug$nodiploma, 
                y = model_aug$.resid, 
                col.int = FALSE,
                xlab = "nodiploma", 
                main = "Binned Residual vs. nodiploma")
arm::binnedplot(x = model_aug$highschoolgrad, 
                y = model_aug$.resid, 
                col.int = FALSE,
                xlab = "highschoolgrad", 
                main = "Binned Residual vs. highschoolgrad")
arm::binnedplot(x = model_aug$homeprice_med, 
                y = model_aug$.resid, 
                col.int = FALSE,
                xlab = "homeprice_med", 
                main = "Binned Residual vs. homeprice_med")
model_aug %>%
  group_by(rural) %>%
  summarise(mean_resid = mean(.resid))
```

The linearity assumption is satisfied. The binned residuals vs. predicted probability plot shows irregularity with a very slight clustering of residual values below 0.0. The binned residuals vs. collegewhite plot shows irregularity. The binned residuals vs. whitecollar plot shows irregularity, with a slight clustering of residual values below 0.0 and a slight increase in residual values as you move right. The binned residuals vs. nodiploma, binned residuals vs. highschoolgrad, and binned residuals vs. homeprice_med show complete irregularity. For the predictor variable rural, which has two categories rural and urban, both mean residuals are very close to zero. There is no strong indication of nonlinearity; therefore, we can assume that there is a linear relationship between log(gent) and the predictor variables.

We created a heat map of residuals to examine the independence assumption:

```{r}
model_aug <- model_aug %>%
    mutate(.rownames=as.numeric(.rownames))
model_aug_merged <- inner_join(merged, model_aug, by = ".rownames")
```

```{r}
ggplot(data = model_aug_merged, aes(fill = .resid)) +
  geom_sf() +
  labs(title = "Research Triangle", 
       subtitle = "Heat Map of Residuals") +
  theme_void() +
  scale_fill_distiller(palette = "BuPu" , guide = "legend")
```


need to change--> To discuss randomness and independence, we must go back to the source of our data. All of the data we are using is sourced from the Census Bureau's annual American Community Survey and official North Carolina demographic data. According to the census sampling techniques and methodology, we can reasonably assume that randomness and independence are satisfied. Read more here: https://www.census.gov/programs-surveys/sipp/methodology.html

### Section 3: Discussion

Now that we've confirmed that it satisfies assumptions, let's take a look at our chosen logistic model again: 

```{r}
tidy(model_aic_full, conf.int = TRUE, exponentiate = FALSE) %>%
  kable(digits = 3, format = "markdown")
```

`log(pi_hat/(1-pi_hat)) = -2.877 + (0.094)*(collegewhite) - (0.055)*(whitecollar) + (0.118)*(nodiploma) + (0.061)*(highschoolgrad) + (0.00001)*(homeprice_med) + (0.891)*(ruralUrban)`


We would like to discuss the variables that have the most impact on the response variable gent. Therefore, we will discuss variables with p-values of <0.05. The variable collegewhite seems to have a reliably strong impact on gent: holding all other variables constant, with a unit change in collegewhite, the odds of gentrification are expected to multiply by a factor of exp(0.089) = 1.093. However, this impact is not as strong as that of the rural variable. According to the model coefficient for the term ruralUrban, holding all other variables constant, the odds of gentrification for an urban area is expected to be 2.55 that of a rural locale. We would like to suggest that the change in college-educated whites in a county and urban character likely greatly impact "gentrification" as we have classified it (a significant decrease in black population). 


Creating a Receiver Operating Characteristic (ROC) curve:

```{r}
(roc_curve <- ggplot(model_aug,
                     aes(d = as.numeric(gent) - 1,
                         m = .fitted)) +
  geom_roc(n.cuts = 10, labelround = 3) +
  geom_abline(intercept = 0) +
  labs(title = "Receiver Operating Characteristic (ROC) curve", 
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)") )
```


```{r}
calc_auc(roc_curve)$AUC
```

Since our AUC 0.742 we can see that the logistic model fits the data fairly well.

There are potential consequences of misclassifying an area as gentrified or not gentrified that we have to consider. If we erroneously classify an area as not gentrified, we could miss an opportunity to control the effects of gentrification and we risk letting growth have far-reaching cultural consequences. It we call an area gentrified, somebody will likely conduct further research on the area before making any policy decisions, so the risk of false-positive classification is not very high.

The Apache Junction Armchairs, being socially responsible policymakers, are more worried about falsely classifying an area as not gentrified than we are about falsely classifying an area as gentrified. The social costs are higher in the former scenario, so we are going to pick a gentrification probability threshold that reflects these priorities.

### Section 4: Limitations


### Section 5: Conclusion


### Section 6: Additional Work


Univariate EDA 

```{r}
p1 <- ggplot(data = manual, mapping = aes(x = privateschool)) + 
  geom_histogram()
p2 <-ggplot(data = manual, mapping = aes(x = collegewhite)) + 
  geom_histogram()
p3 <-ggplot(data = manual, mapping = aes(x = homeprice_med)) + 
  geom_histogram()
p4 <-ggplot(data = manual, mapping = aes(x = income_med)) + 
  geom_histogram()
p5 <-ggplot(data = manual, mapping = aes(x = moved)) + 
  geom_histogram()
p11 <-ggplot(data = manual, mapping = aes(x = nodiploma)) + 
  geom_histogram()
p12 <-ggplot(data = manual, mapping = aes(x = highschoolgrad)) + 
  geom_histogram()
p13 <-ggplot(data = manual, mapping = aes(x = collegedegree)) + 
  geom_histogram()
p1 + p3 + p2 + p4
p5 + p11 + p12 + p13
```

Each predictor variable is normally distributed around 0.


Bivariate EDA: 

```{r}
p6 <- ggplot(data = manual, mapping = aes(x = gent, y = privateschool)) + 
  geom_boxplot()
p7 <- ggplot(data = manual, mapping = aes(x = gent, y = collegewhite)) + 
  geom_boxplot()
p8 <- ggplot(data = manual, mapping = aes(x = gent, y = moved)) + 
  geom_boxplot()
p9 <- ggplot(data = manual, mapping = aes(x = gent, y = income_med)) + 
  geom_boxplot()
p10 <- ggplot(data = manual, mapping = aes(x = gent, y = homeprice_med)) + 
  geom_boxplot()
p14 <- ggplot(data = manual, mapping = aes(x = gent, y = nodiploma)) + 
  geom_boxplot()
p15 <- ggplot(data = manual, mapping = aes(x = gent, y = highschoolgrad)) + 
  geom_boxplot()
p16 <- ggplot(data = manual, mapping = aes(x = gent, y = collegedegree)) + 
  geom_boxplot()
p6 + p7 + p8 + p9
p10 + p14 + p15 + p16
```

The relationship between the response variable "gent" and the predictor variables are all each roughly normal.
